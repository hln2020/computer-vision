{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader and Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_iou(prediction,mask):\n",
    "  mask = torch.tensor(mask).int()\n",
    "  prediction = torch.tensor(prediction).int()\n",
    "  wrong = 0\n",
    "  right = 0\n",
    "  total = 0\n",
    "\n",
    "  # iterate through values\n",
    "  for m,p in zip(mask.view(-1), prediction.view(-1)):\n",
    "      m = m.item()\n",
    "      p = p.item()\n",
    "      if p == 0 and m == 0:\n",
    "          pass\n",
    "      elif p == m:\n",
    "          right+=1\n",
    "          total+=1\n",
    "      else:\n",
    "          wrong+=1\n",
    "          total+=1\n",
    "  return right/total\n",
    "\n",
    "def compute_single_iou(prediction, mask):\n",
    "  \"\"\"\n",
    "  Calculates Intersection-over-Union (IoU) for a single prediction and mask tensor.\n",
    "\n",
    "  Args:\n",
    "      prediction: A torch tensor of shape (..., H, W) representing the predicted mask.\n",
    "      mask: A torch tensor of shape (..., H, W) representing the ground truth mask.\n",
    "\n",
    "  Returns:\n",
    "      A float value representing the IoU between the prediction and the mask.\n",
    "  \"\"\"\n",
    "\n",
    "  # Flatten tensors (optional, depending on use case)\n",
    "  prediction = torch.tensor(prediction.flatten())\n",
    "  mask = torch.tensor(mask.flatten())\n",
    "\n",
    "  # Intersection\n",
    "  intersection = torch.sum((prediction == mask) & (prediction != 0))\n",
    "\n",
    "  # Union (avoiding division by zero)\n",
    "  union = torch.sum(prediction != 0) + torch.sum(mask != 0) - intersection\n",
    "\n",
    "  # IoU (avoid division by zero)\n",
    "  iou = torch.where(union != 0, intersection.float() / union.float(), 0.0)\n",
    "\n",
    "  return iou.item()\n",
    "\n",
    "def get_number(filename):\n",
    "  return int(filename.split(\"_\")[1].split(\".\")[0]) # extract the number part from the filename (excluding extension)\n",
    "\n",
    "\n",
    "def encode_labels(mask):\n",
    "    encoded_mask = np.zeros((mask.shape[0],41,mask.shape[1], mask.shape[2]))\n",
    "    \n",
    "    for i in range(len(mask)):\n",
    "        for k in np.arange(0,41): # for class in classes\n",
    "            encoded_mask[i][k] = mask[i]==float(k)\n",
    "        return encoded_mask\n",
    "\n",
    "def decode_prediction(prediction_mask):\n",
    "    decoded_prediction = np.zeros((1, prediction_mask.shape[0], prediction_mask.shape[1]))\n",
    "    max_indices = np.argmax(prediction_mask, axis=0)\n",
    "    decoded_prediction = max_indices\n",
    "    return decoded_prediction\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "  def __init__(self, root_dir=\"dataset/train\", transform=None, train=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      data_path (str): Path to the data directory.\n",
    "      transform (callable, optional): A function for transforming data. Defaults to None.\n",
    "    \"\"\"\n",
    "    all_paths = []\n",
    "    masks = []\n",
    "    self.train = train\n",
    "\n",
    "    for video in os.listdir(root_dir): # for every video in train\n",
    "        # get names of all video folders\n",
    "        if \"DS_Store\" not in video: \n",
    "            dirlist = os.listdir(os.path.join(root_dir, video)) \n",
    "            dirlist = [path for path in dirlist if \"png\" in path]\n",
    "            sorted_dirlist = sorted(dirlist, key=get_number)\n",
    "\n",
    "            # collect image paths and masks -> append to master list\n",
    "            if self.train: \n",
    "              mask = np.load(os.path.join(root_dir, video, \"mask.npy\"))\n",
    "              masks.append(mask)\n",
    "            images_paths = [os.path.join(root_dir, video,image_path) for image_path in sorted_dirlist]\n",
    "            all_paths.append(images_paths)\n",
    "    \n",
    "    if self.train:\n",
    "      masks = [mask for mask in masks if mask.shape==(22, 160, 240)]\n",
    "      masks = np.array(masks)\n",
    "      self.masks = masks.reshape(masks.shape[0]*masks.shape[1],masks.shape[2],masks.shape[3])\n",
    "    else: masks = None\n",
    "    self.all_paths = np.array(all_paths).flatten()\n",
    "    self.transform = transform  # Optional transformation for data\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    Returns the length of the dataset.\n",
    "    \"\"\"\n",
    "    return len(self.all_paths)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      index (int): Index of the data point to return.\n",
    "\n",
    "    Returns:\n",
    "      tuple: A tuple containing the data and its corresponding label.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if index>=len(self.masks):\n",
    "      index = 0\n",
    "\n",
    "    image = Image.open(self.all_paths[index])  # access data from path based on index\n",
    "    image = np.asarray(image,dtype='int32').astype(np.uint8)\n",
    "    if self.train:\n",
    "      mask = self.masks[index]\n",
    "      # Apply transformation if defined\n",
    "      if self.transform:\n",
    "        image = self.transform(image)\n",
    "      return (image, mask)\n",
    "    else: return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u-net model definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder path\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Decoder path\n",
    "        self.up6 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv7 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.up8 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv9 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(64)\n",
    "        self.conv10 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,3,1,2).float()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        encoder1 = x\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        encoder2 = x\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.up6(x)\n",
    "        x = torch.cat([x, encoder2], dim=1)\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.up8(x)\n",
    "        x = torch.cat([x, encoder1], dim=1)\n",
    "        x = F.relu(self.bn9(self.conv9(x)))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare device for running on gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# hyperparams\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "model = UNet(3,41)\n",
    "model.to(device)\n",
    "model_folder = \"models\"\n",
    "\n",
    "# learning params\n",
    "criterion = nn.CrossEntropyLoss()  # Binary Cross Entropy for segmentation\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)# lr=0.001)\n",
    "\n",
    "# dataset\n",
    "train_dataset = SegmentationDataset(root_dir='../dataset/train', train=True)\n",
    "val_dataset = SegmentationDataset(root_dir='../dataset/val')\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,  # Adjust batch size as needed\n",
    "                              shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                              batch_size=batch_size,  # Adjust batch size as needed\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "total_val_loss = []\n",
    "total_val_iou = []\n",
    "total_iou = []\n",
    "# clear textfile for dumping results\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  losses = []\n",
    "  ious = []\n",
    "  print(f\"Epoch {epoch} training\")\n",
    "  for data, label in tqdm(train_dataloader):\n",
    "    # Forward pass\n",
    "    new_data = transforms(torch.tensor(data)).to(device)\n",
    "    prediction = model(new_data)\n",
    "    loss = criterion(prediction,torch.tensor(encode_labels(label)).to(device))\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(loss)\n",
    "    prediction = np.array([decode_prediction(pred.detach().cpu()) for pred in prediction])\n",
    "    for p, l in zip(prediction, label.cpu().numpy()):\n",
    "        ious.append(compute_single_iou(prediction,label.cpu().numpy()))\n",
    "\n",
    "  print(f\"Train Mean Loss: {np.mean(np.array(losses))}\")\n",
    "  # validation\n",
    "  print(f\"Epoch {epoch} validation\")\n",
    "  val_losses = []\n",
    "  val_ious = []\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    for val_data, val_label in tqdm(val_dataloader):\n",
    "      val_data = transforms(torch.tensor(val_data)).to(device)\n",
    "      val_label = torch.tensor(val_label).to(device) # move data and label to device\n",
    "      val_prediction = model(val_data)\n",
    "      loss = criterion(val_prediction,torch.tensor(encode_labels(val_label.cpu())).to(device))\n",
    "      val_losses.append(loss.item())\n",
    "      val_prediction = np.array([decode_prediction(val_pred.cpu()) for val_pred in val_prediction])\n",
    "      for p, l in zip(val_prediction, val_label.cpu().numpy()):\n",
    "        val_ious.append(compute_single_iou(val_prediction,val_label.cpu().numpy()))\n",
    "  total_loss.append(np.mean(np.array(losses)))\n",
    "  total_val_loss.append(np.mean(np.array(val_losses)))\n",
    "  total_val_iou.append(np.mean(np.array(val_ious)))\n",
    "  total_iou.append(ious)\n",
    "\n",
    "  print(f\"Validation Mean Loss: {np.mean(np.array(val_losses))}\")\n",
    "  print(f\"Validation Mean IOU: {np.mean(np.array(val_ious))}\")\n",
    "\n",
    "\n",
    "\n",
    "  torch.save(model.state_dict(),f'{model_folder}/model_{epoch}.pth') # save model every epoch\n",
    "  model.train()\n",
    "\n",
    "  # save epoch metrics\n",
    "\n",
    "  # visualize results\n",
    "  print(f\"Epoch: {epoch+1}, Loss: {np.average(losses):.4f}\")\n",
    "  plt.imshow(data[0])\n",
    "  plt.title(\"Original Image\")\n",
    "  plt.show()\n",
    "  plt.imshow(decode_prediction(prediction))\n",
    "  plt.title(\"Predicted Mask\")\n",
    "  plt.show()\n",
    "\n",
    "with open(f\"{model_folder}/metrics.pkl\") as f:\n",
    "  pickle.dump([total_loss,total_validation_loss,total_iou])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image in val_dataloader:\n",
    "        print(image.shape)\n",
    "        prediction = model(image.to(device))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results on Saved Model (later epochs not necessarily better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3,41)\n",
    "model.load_state_dict(torch.load(\"models/model_6.pth\")) # change to reflect model path\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0,len(val_dataset)-1) # random index in dataset\n",
    "data = (val_dataset[i][0]) # first image in batch\n",
    "mask = torch.tensor(val_dataset[i][1])\n",
    "new_data = transforms(torch.tensor(data)).to(device).unsqueeze(0) # transform and fit to expected size for model\n",
    "prediction = decode_prediction(model(new_data)[0].cpu().detach())\n",
    "plt.imshow(data)\n",
    "plt.show()\n",
    "plt.imshow(prediction)\n",
    "plt.show()\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = 0\n",
    "right = 0\n",
    "total = 0\n",
    "# iterate through values\n",
    "for m,p in zip(mask.view(-1), prediction.view(-1)):\n",
    "    m = m.item()\n",
    "    p = p.item()\n",
    "    if p == 0 and m == 0:\n",
    "        pass\n",
    "    elif p == m:\n",
    "        right+=1\n",
    "        total+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "        total+=1\n",
    "\n",
    "print(right/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(mask>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(prediction>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (val_dataset[i][0]) # first image in batch\n",
    "mask = torch.tensor(val_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(mask!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(prediction!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
